\chapter{Conclusions \& looking ahead} \label{chapter:conclusions}

Despite the recent success of deep learning, it still lacks some of the features of human intelligence. In this dissertation, I have focused on how humans are able to reuse our knowledge flexibly in new tasks, before we have any data on those tasks. I have suggested that a computational mechanism underlying this is an ability to transform prior task representations to adapt them to a new task. I have proposed meta-mapping -- higher-order tasks that transform task representations -- as a computational model of this type of adaptation. \par
In order to evaluate this idea, I have provided a parsimonious implementation of the meta-mapping framework in the form of Homoiconic Meta-Mapping (HoMM) architectures. I have demonstrated the effectiveness of HoMM by showing its zero-shot task performance across a wide variety of domains, from polynomial regression to visual classification and reinforcement learning. HoMM is often able to achieve 80-90\% performance on a new task with no data on that task at all. This brings deep learning models a step closer to human-like flexibility. This work therefore has implications for both cognitive science and artificial intelligence. In this chapter I will review these contributions, and their broader implications. \par  

\section{Contributions}

I have proposed meta-mappings as a computational account of the human ability to perform a novel task zero-shot (without any data), based on the relationship between the novel task and prior tasks. The fundamental idea is that tasks should be performed from a task representation, and that adaptation can be implemented as a transformation of a task representation. Thus adaptation can be interpreted as a meta-mapping, a higher-order task that maps between representations of more basic tasks. \par  

To instantiate this idea, I have proposed HoMM architectures. These architectures embed data points, tasks, and meta-mappings into a shared representational space, and use shared systems to infer and execute transformations of that space. That is, the same systems are used regardless of the entities (data, tasks, etc.) over which a computation is being executed. Sharing the representational space and transformation systems is parsimonious --- it does not multiply networks unnecessarily. Furthermore, I see this proposal as a logical development from the fundamental idea of meta-learning: that tasks themselves can be seen as data points in a higher-order task. This leads to the reciprocal idea of transforming task representations just like we manipulate data, i.e. a \emph{homoiconic} approach. \par  

I have shown that meta-mapping, as implemented in the HoMM architecture, performs well across a wide range of settings. The computational paradigms I considered range from regression to classification to reinforcement learning, with inputs ranging from simple multi-hot vectors to images. Across these settings, HoMM often achieves 80-90\% performance on a new task without data from that task, based on the relationship between the new task and a prior task. When given enough experience with the task space, as in the visual classification settings with enough training tasks, it is able to achieve perfect adaptation. In many runs (though not all), it is even able to do so with held-out meta-mappings. \par

\textbf{Language generalization:} I compared HoMM to the standard paradigm of zero-shot learning --- constructing a task representation from natural language \citep[e.g.][also see below]{Larochelle2008}. While language-based generalization can be effective, our HoMM approach is generally more sample efficient at generalizing to tasks far outside its training experience, at least in the settings we considered. That is, HoMM needs fewer training tasks to generalize well zero-shot. While the language model performs comparably at interpolating to closely related tasks, as in the visual concepts domain, HoMM appears to offer stronger extrapolation to tasks farther from those on which it has been trained. This effect is demonstrated clearly when the new tasks directly contradict prior tasks, as in the card games and RL domains.\par

Furthermore, HoMM seems to exhibit more systematic generalization than the language-conditioned models. For example, HoMM resulted in more runs with perfect generalization at moderate-sample sizes in the visual concept tasks, while the language generalization results were more graded. HoMM also exhibited more strongly correlated performance on the held-out RL tasks --- when it was performing well on one of the tasks, it was performing well on the other. This is more like the systematic behavior that humans often exhibit. \par

\textbf{Some notes of caution:} However, these results should not be interpreted as suggesting that language is not important or useful. Instead, language and meta-mapping should be seen as complementary. They may be applicable in different domains, and could potentially be mutually supporting. Cognition is complex, and any single model is guaranteed to be an oversimplified approximation of human cognitive processes in real-world situations. Indeed, an interesting future direction would be to consider how meta-mapping and language can mutually constrain one another when adapting to a new situation. I am not claiming that meta-mapping is the only cognitive mechanism for adaptation. Instead, my results demonstrate that meta-mapping may be useful as one tool for building models with more human-like adaptibility.  \par

\textbf{Adaptation as a starting point:} I would also like to highlight the results showing that meta-mapping provides a useful starting point for later learning. While meta-learning approaches often construct a good starting point for learning any task from the known distribution, they do not use task relationships to offer a uniquely valuable starting point for each novel task. My results show that starting from adapting a prior task can substantially reduce the errors made along the way to mastering the new task. The efficiency of human learning may be partly explained by adaptation before beginning the task. \par 

\textbf{Summary:} HoMM provides a model of a possible computational mechanism underlying cognitive adaptibility, and the role that adaptibility may play in future learning. Language likely plays an important role as well, and future work should explore uniting these approaches. 

\section{On flexibility in natural and artificial intelligence}

In the introduction, I noted how researchers in cognitive science have aggressively critiqued deep learning for its lack of flexibility \citep[e.g.][]{Lake2015, Lake2016, Lake2017, Marcus2018}. We have addressed one challenging aspect of flexibility in this work -- the ability to take our knowledge of a task, and adapt to some variation. While this might be challenging for standard deep-learning models, the general framework of meta-mapping makes it possible. Thus, at their most basic level, these results present a challenge for those who would say deep-learning models are too inflexible to be accurate cognitive models. \par  
Indeed, I see my project as following in the tradition of work that explores how systematic, structured generalization can emerge from the structure of learning experience, without needing to be built into the model itself \citep{McClelland2010a, McClelland2010, Hansen2017}. This is a challenge to arguments that cognition must rely on strictly compositional representations in order to exhibit systematic and productive generalization \citep[e.g.][]{Fodor2001, Fodor2008lot2, Lake2017}. Without building in compositional representations of tasks, our model can learn to exploit the shared structure in the concept of ``losing'' across a few card games to achieve 85\% performance in losing a game it has never tried to lose before. \par 

There are a number of potential benefits to letting the compositional structure emerge. First, the structure does not need to be hand-engineered specially for each domain. Our system required no special knowledge about the domains beyond the basic tasks and the relationships between them. The fact that some of these relationships corresponded to e.g. permutations of variables in the polynomial domain did not need to be hard-coded, instead the model was able to discover it from the patterns of the mappings (presumably, since it was able to generalize well to held-out permutations). The second advantage of letting compositionality emerge is that it can potentially allow for novel decompositions at test time. The ability of our model to perform well on held-out meta-mappings supports this hope, but further work will be needed to verify it. \par

In summary, I suggest that meta-mapping offers a way to create models that can bring deep learning systems closer to the flexibile intelligence of the human mind. While I have demonstrated these results in some simple settings, one of the powerful features of deep learning is that its results tend to improve as datasets grow more complex and realistic \citep{Hill2019a,Radford2019,Sutton2019}. I hope that this research will help guide the way to building even more flexible models in more realistic domains.  \par

\section{Relating to cognitive science}

Our work provides a tool for modeling human adaptibility, which has many potential direct applications. It offers an explanation for how humans might be able to adapt when told ``watch out, the floor is slippery,'' or recognize a pink-and-green striped car even if they have never seen one before, by transforming their task representations. This is a fundamental aspect of human intelligence, but is often omitted from cognitive models. However, our work has broader relevance as well. \par 

\textbf{Fast and slow transfer:} In Chapter \ref{chapter:introduction}, I reviewed the cognitive science and machine learning literatures from a Complementary Learning Systems perspective. In particular, I sugested that humans' slow learning of shared structure in the world can itself provide transfer benefits, but also helps set up the representations necessary for faster transfer mechanisms. This idea is reflected in the organization of the HoMM architecture. A great deal of perceptual and action processing is shared across tasks (though see below), so that the model can exploit the shared visual features of different games or objects. The representations constructed by these shared systems are used for both task inference and for task performance. This allows the system to perform a novel task from a few examples (as in standard meta-learning), or based solely on its relationship to prior tasks, by meta-mapping. The fast zero-shot transfer achieved by meta-mapping thus relies on the representations of tasks and data that are constructed over the full development of the network. \par

Furthermore, this fast transfer ability itself must be learned over time. However, once it has been learned, it can then generalize to new examples and even new meta-mappings. This reflects my suggestion that humans not only learn good representations for fast transfer, but actively practice the act of adaptation. I hope my work will inspire broader thought about how different systems of transfer, operating over different timescales, can support each other in order to achieve the flexibility of human intelligence.\par

\textbf{Abstraction \& recursion:} Abstraction \& recursion offer one exciting area where our model could potentially offer a new modeling framework. It would be interesting to explore how concepts can be recursively built upon other concepts, as happens in learning of mathematics \citep{Wilensky1991, Hazzan1999, Lampinen2017b}. For example, addition can be seen as repeated succession, multiplication can be seen as repeated addition, exponentiation as repeated multiplication, and this process is recursively continued in up-arrow notation. A homoiconic system like HoMM seems closer to being able to capture this recursive construction of concepts. It would be interesting to explore how our architectures could model this type of recursive construction of concepts. \par 

Relatedly, I believe that my model moves closer to capturing some of the recursive processing that Jerry Fodor and others have considered to be important \citep[e.g.][]{Fodor2008lot2}. I have drawn particular inspiration from ideas about how humans re-represent their knowledge into more generalizable forms \citep{Karmiloff-Smith1986,Clark1993}. As a reminder, that work examines fascinating developmental trajectories where, even after initial behavioral mastery of some concept is achieved, various implicit and explicit measures of understanding continue to evolve. It would be interesting to explore whether auxiliary learning objectives over task representations and meta-mappings, and the shaping effects of language (see below), could model some of these phenomena. Could the change in behavior on a particular task be driven by the evolution of its task representation while learning a meta-mapping involving that task? Could unsupervised learning over task representations make clusters and structure within the space of tasks salient, thereby regularizing and structuring behavior? Exploring these questions will be an exciting direction for future work. \par 

\textbf{Consciousness:} I have also been inspired by computational models of how conscious knowledge may be built on top of implicit knowledge \citep{Cleeremans2014}, as well as by the Global Workspace Theory \citep{Baars2005}. HoMM's shared representational space for data points, tasks, and meta-mappings can be seen as a global workspace, over which task-specific computations can be executed. Indeed, the HoMM architecture could potentially shed light on issues about explicit vs. implicit knowledge --- it is plausible to assume that a task representation captures what we know about a task, while implicit knowledge could be captured both by the task representation and elsewhere (such as in the default weights of the task network). Exploring these ideas further could provide an exciting direction for future work. \par

\textbf{Modularity vs. generality:} The issues above also relate to ideas Fodor expressed about the modular structure of the mind, for example the view of mental processes as ``transforming internal representations'' and that what is accessible about the stimulus is only ``what is given in [...] its \emph{proximal} representations'' \citep[][pp. 200-201]{fodor1975language}. Indeed, the division of the HoMM architecture into input and output systems, with flexible, task-specific computations in the middle may seem very reminiscient of the type of modularity that he sometimes advocated \citep{Fodor1983modularity}. HoIver, I chose this implementation as a simplifying assumption --- I believe that in reality processes such as perception are not task-independent, but involve the interaction of top-down and bottom-up constraints \citep{McClelland2014}. \par

Reciprocally, I also believe that higher-level computations are influenced and constrained by the modalities in which they are supported. This computational feature can emerge in the HoMM model, as despite the fact that different types of data and tasks are embedded in a shared latent space, the model generally learns to organize distinct types of inputs into somewhat distinct regions of this space. This means that the task-specific processing can potentially usefully exploit domain-specific features of the input, as for example humans do when they use gestures to think and learn in spatial contexts like mathematical reasoning \citep{Goldin-Meadow1999, Wakefield2018}. At the same time, the shared space can allow a graded overlap in the structure that is shared across different input domains. That is, the HoMM model is able to learn what should be shared and what should be separated, whereas approaches that build such divisions in are fundamentally more limited.\par

\textbf{Language:} I noted above that our results should not be taken as a rejection of the role of language. Instead, they suggest that meta-mapping and language could be mutually supporting. It would be interesting to explore whether combining the representations produced by the language system and meta-mapping system could result in better performance than either alone, especially if this combination were weighted by some measure of uncertainty in the estimates. Furthermore, while we considered language input only in these projects, language output (explaining behavior) plays an important role in learning, both in humans \citep{Chi1994}, and in neural networks \citep{Mu2019}. While our use of task-representation-classification in some settings may have captured some aspects of this, adding richer explanations during learning will likely be important for achieving truly human-like behavior. 

\textbf{Cognitive control:} Furthermore, although it is not my primary focus in this project, the HoMM architecture may have interesting connections to cognitive control. Even without meta-mapping, the HoMM architecture instantiates an architecture that can compute flexibly in response to task demands, provided as examples or natural language. Futhermore, the ``default'' task-network weights output by the HyperNetwork could be used to model more automatic processing, which more cognitive, task-specific processing might need to override. I showed some initial experiments related to this in Chapter \ref{chapter:zero_shot_via_homm}. Meta-mapping adds many additional directions --- for example, a failure to meta-map perfectly could capture some of the challenges of task-switching. Exploring these ideas further would also be an interesting direction for future work. \par

\textbf{Neuroscience:} Finally, a major advantage of neural network models is their ability to make predictions about neuroscience. For example, neural network models have been used to understand aspects of the neural basis for perception \citep{Yamins2016a}, semantic cognition \citep{Rogers2004}, and cognitive control \citep{Shenhav2013}. We have not engaged with this level of analysis, but doing so would be an exciting direction for future work. Our HoMM architecture offers a framework that can unify perception, task representation, control, and motor outputs, all within a single model. It would be possible to relate the different components of our model to different brain regions --- visual perception to visual cortex, higher level perceptual features to more semantic regions, the action network to motor cortex, and the meta/hyper/task networks to frontal regions associated with task representation/control/working memory. Thus, our architecture could potentially provide an integrative model spanning a wide range of brain regions, although it would likely require some modifications to account for neural data well (some of which are discussed in the limitations section below). \par 

\textbf{Summary:} I take an emergent perspective on the structure of the mind, and believe that all cognitive and perceptual processes are mutually influencing and supporting. For simplicity my model does not always fully reflect this. Furthermore, I believe my approach may be broadly useful, even to researchers with different perspectives. The functional approach relates to the ideas of Fodor and Karmiloff-Smith, the perspective on adaptation draws inspiration from prior work on analogy and transfer, and the HoMM architecture could even have interesting implications for researchers interested in cognitive control or neuroscience. I hope that researchers from many of these areas will find my work inspirational.

\section{Relating to artificial intelligence}

There are a number of potential direct applications in artificial intelligence, from building more flexible vision models to building better systems for robotics. Domains like robotics are especially interesting from the meta-mapping perspective, because exploration in real world settings is costly and must be safe \citep{Turchetta2016}, and so the substantial reduction in errors made when using meta-mapping as the starting point for learning a new task may be valuable. \par 

\textbf{Reinforcement learning:} Applying meta-mapping to different types of adaptation in RL also opens many possibilites, especially in combination with model-based methods. Meta-mapping could be used as a principled way of adapting transition functions or successor representations \citep[c.f.][]{Madarasz2019}, beyond the approach of adapting model-free reward or value estimates that we demonstrated. While adapting pure model-free RL will likely be challenging in more complex task spaces, combining meta-mapping with other insights could yield much greater flexibility. For example, meta-mapping could be used with hierarchical models where language has been used as a task or sub-task representation \citep[e.g.][]{Jiang2019}. Similarly, it could be applied in planning based models, for example using monte-carlo tree search \citep[as in e.g.][]{Silver2016, Silver2017}, but with task-representation-conditioned policy and value functions. More ambitiously, meta-mapping could be explored in models that learn to plan \citep{Guez2019} rather than having that planning hand-engineered into the architecture. Many contemporary RL frameworks could potentially be augmented with meta-mapping. \par

\textbf{Abstraction:} Many of the directions of future investigation from a cognitive perspective relate to pressing problems in artificial intelligence as well. The issue of flexible abstraction is challenging in deep learning --- while feed-forward neural networks generally construct progressively more abstract representations in higher layers, the relationships between those representations are fixed by the fixed computational pathway. The shared representational space and meta/hyper networks in our model provide a suggestion for how concepts at different levels of abstraction could be integrated and used more flexibly. This would be another important step towards human-like flexibility. \par 

\textbf{Continual learning:} Finally, the work in Chapter \ref{chapter:timescales} suggests new directions in continual learning. By off-loading much of the task-specific computation to a flexible hyper-network-based architecture, and inferring and optimizing a task representation, we can enable learning of a new task without even the possibility of interfering with prior tasks. Furthermore, we can leverage our knowledge of prior tasks to learn faster than we would have in an untrained model, or without meta-mapping. This positive transfer is very different from the standard in continual learning, which mostly focuses on stemming the bleed in accuracy caused by new tasks, even in more recent works that have also incorporated hyper networks \citep{Oswald2020}. Given the importance of learning rapidly on new tasks, without interfering with prior knowledge, this is also an exciting future direction. \par 

\textbf{Summary:} In addition to the direct applications of the meta-mapping framework in building more flexible artificial intelligence systems, it suggests many exciting future directions in reinforcement learning, abstraction, and continual learning. I hope that this project will help inspire the development of deep learning systems that can adapt and learn more like humans. \par 

\section{Limitations of the present explorations}

While I have explored HoMM in a relatively broad range of computational paradigms, I have still only explored a single family of architecture within a small subset of the computational paradigms that can be found in the literature. In this section I will outline a few limitations of the present work, and corresponding ideas for future research, but note these are simply examples of the many choices made in this project that could be explored further. \par

There are a number of architectural aspects of the approach that could be altered. For example, although we used HyperNetworks to parameterize our task network, it would also be reasonable to have a fixed task network which simply receives the task representation as an additional input. We evaluated this approach in the polynomial and RL domains, and found it did not perform as well at meta-mappings (although it performed similarly at the basic tasks). However, it might be a useful approach in some settings. We also noted in the visual categories domain that linear task networks seemed to improve meta-mapping, while nonlinear ones seemed to result in better basic task performance --- thus it might be reasonable to consider a deep, nonlinear task network, but with a linear skip-connection from beginning to end. An identity (ResNet-like) inductive bias on this linear connection might be helpful as well, so that the network would only have to learn what to change about the task representation. \par 

Furthermore, although we found that homoiconic architectures were useful, it might be that in some task domains a shared representational space with shared networks across different types of tasks is detrimental. In general, whether sharing an architecture across different tasks is beneficial depends on the data regime --- shared architectures can be a useful regularizer with small datasets, but correspondingly harmful with sufficiently large ones. Thus, the answer to this question will likely depend on the depth and breadth of the training data. One cognitively-motivated intermediate option might be to have a domain general shared-system like ours, but with additional learning of more domain-specific mappings directly from inputs to outputs, which could potentially allow for the benefits of both approaches.\par

As a more general point, cognitive processing is much more complex than our model. While we relied on simple feed-forward computations for our simple tasks, using a recurrent task network, or even a more complex architecture involving memory --- such as the Differentiable Neural Computer \citep{Graves2016} --- would likely increase the ability of the model to perform and adapt on complex tasks. This would likely be necessary to reach human-level performance in many domains.\par 

Finally, the type of flexibility we have proposed is still limited in some crucial ways. It requires exactly identifying the prior task to use as a source for the adaptation, and when that adaptation should occur (i.e. where the task boundary is). It would be more realistic to relax these assumptions. This could be achieved by combining with techniques that have been used for task-change tracking in meta-learning \citep[e.g.][]{Nagabandi2019}, but could also potentially be learned end-to-end in an appropriate model given appropriate input. There are a number of linguistic cues that humans can exploit for when they should try to adapt, and a system that experiences many such transitions might learn when adaptation is warranted. \par 


\section{Looking ahead}

The next ten years will likely bring us a great deal more clarity about how far deep learning is from achieveing human-like intelligence. As I suggested in the introduction, it may be that greater scale and complexity of our architectures and training regimes will bring forth more flexible behavior from many deep neural network models. Indeed, this is almost certainly true to some extent --- overparameterization and larger datasets both tend to improve the generalization performance of deep neural networks. If translation abilities can emerge from a word-prediction model given enough data \citep{Radford2019}, couldn't the ability to adapt emerge from simple architectures trained in complex enough environments? If so, what will the contribution of this dissertation be to our future knowledge? Will it be more than another ``bitter lesson'' demonstrating that ``building in how we think we think does not work in the long run'' \citep{Sutton2019}? \par 

From an artificial intelligence perspective, even if more flexible behavior emerges in other architectures when they are placed in richer training regimes, the architectural and training innovations I have proposed in this work may still provide useful insights that allow flexibility to emerge at more feasible data scales. Many applications of artificial intelligence (from medical diagnosis to self-driving cars) would benefit from models with greater flexibility within a family of related tasks. The perspective of building and transforming task representations may also inspire future work that leverages similar abstractions --- perhaps architectures that use task-representation and HyperNetwork-based approaches like ours will be better able to accommodate diverse sets of tasks from different domains, or will be useful for challenging new evaluations of intelligence \citep[e.g.][]{Chollet2019}. \par 

From a cognitive science perspective, my work provides a computational basis for understanding the flexibility of the human mind. Cognitive modeling is always a trade-off between capturing details of the system and phenomena, and simplifying the system to make it more comprehensible; emergent behavior is generally harder to analyze than the behavior of simpler models. Models like those I have proposed here, which offer an intermediate amount of structure, may offer a useful level of complexity that allows for flexible behavior to be learned in complex task spaces (rather than built in), while also making the representational and computational basis for that flexibility available to analysis. Our architectures may also provide a framework for instantiating neuroscientific theories of higher-level cognitive processing. \par 

Ultimately, I have presented one computational perspective on how natural and artificial intelligence could flexibly adapt to new situations. I am excited to see the new perspectives the future will bring, and I hope my work will provide some inspiration for some of them. 
