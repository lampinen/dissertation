\chapter{Conclusions \& looking ahead} \label{chapter:conclusions}

While artificial intelligence has achieved incredible things in recent years, there are still immense differences between artifical and natural intelligence. In this dissertation, I have focused on how humans are able to reuse our knowledge flexibly in new tasks, before we have any data on them. I have suggested that one mechanism underlying this is an ability to transform prior task representations to adapt them to the new task. I have proposed meta-mapping -- higher-order tasks that transform task representations -- as a plausible computational mechanism for this adaptation. I have provided a parsimonious implementation of this framework in the form of Homoiconic Meta-Mapping. I have demonstrated the effectiveness of HoMM by showing its zero-shot task performance across a wide variety of domains, from polynomial regression to visual classification and reinforcement learning. HoMM is often able to achieve 90\% performance on a new task with no data on that task at all. This brings deep learning models a step closer to human-like flexibility. It therefore has implications for both cognitive science and artificial intelligence. \par  

\section{On flexibility in minds and machines}

In the introduction, I noted how researchers in cognitive science have aggressively critiqued deep learning for its lack of flexibility \citep[e.g.][]{Lake2015, Lake2016, Lake2017, Marcus2018}. We have addressed one challenging aspect of flexibility in this work -- the ability to take our knowledge of a task, and adapt to some variation. While this might be challenging for standard deep-learning models, our general framework of meta-mapping makes it possible. Thus, at their most basic level, these results present a challenge for those who would say that deep learning models are inflexible, and therefore are inappropriate models for cognitive processes. \par  

Indeed, we see our work as following in the tradition of work that explores how systematic, structured generalization can emerge from the structure of learning experience, without needing to be built into the model \citep{McClelland2010a, McClelland2010, Hansen2017}. Without building in compositional representations of tasks, our model can learn to exploit the shared structure in the concept of ``losing'' across a few card games to achieve 85\% performance in losing a game it has never tried to lose before. There are a number of potential benefits to letting the compositional structure emerge --- for example, it could potentially allow for novel decompositions at test time. Indeed, the ability of our model to switch to losing a game it has never tried to lose before is somewhat like inferring a novel decomposition, but we would hope that a model with richer training data could make much larger inferential leaps. The ability of our model to perform well on held-out meta-mappings supports this hope, but further work will be needed to verify it. \par

Futhermore, while we showed in some cases that the tasks and meta-mappings could be specified by language, we often specified them by examples of the task mapping. This does not necessarily mean that using language in the other settings would not work -- it is simply that the time and computational resoucess I had available to me while working on this project were finite. It is likely that language could mediate meta-mapping (and the cueing of examples) in more settings and more complex ways than we have explored here.\par 

Indeed, an interesting future direction would be to consider how meta-mapping and language can mutually constrain one another when adapting to a new situation, and how they can interact with learning from examples in more complex ways than we explored in Ch. \ref{chapter:timescales}. Cognition is complex, and any single model is guaranteed to be an oversimplified approximation of human cognitive processes in real-world situations. Our results should not be taken as a suggestion that meta-mapping is the only cognitive mechanism for adaptation. Instead, our results demonstrate that meta-mapping may be useful as one tool for building models with more human-like adaptibility. \par

With these caveats in mind, however, I believe that meta-mapping offers a way to create models that can bring the intelligence of deep learning systems closer to the flexibility of the human mind. While we have demonstrated these results in some simple settings, one of the powerful features of deep learning is that its results tend to improve as datasets grow more complex and realistic \citep{Hill2019a,Radford2019}. We hope that our research will help guide the way to building even more flexible models in more realistic domains.  \par

\section{Relating to cognitive science}

Our model provides a tool for modeling human adaptibility, which has many potential direct applications. It offers an explanation for how humans might be able to adapt when told ``watch out, the floor is slippery,'' or recognize a pink-and-green striped car even if they have never seen one before, by transforming their task representations. However, our work has broader implications as well. \par 

First, our architecture opens up possibilites for exploring abstraction and recursion in cognition more broadly. It would be interesting to explore how concepts can be recursively built upon other concepts, as happens in learning of mathematics \citep{Wilensky1991, Hazzan1999, Lampinen2017b}. For example, addition can be seen as repeated succession, multiplication can be seen as repeated addition, exponentiation as repeated multiplication, and this process is recursively continued in up-arrow notation. A homoiconic system like HoMM seems closer to being able to capture this recursive construction of concepts. It would be interesting to explore how our architectures could be used for modeling learning in similar settings. \par 

Relatedly, some of the inspiration for my work comes from long-standing ideas in cognitive science about how humans re-represent their knowledge into more generalizable forms \citep{Karmiloff-Smith1986,Clark1993}. That work examines fascinating developmental trajectories where, even after initial behavioral mastery of some concept is achieved, various implicit and explicit measures of understanding continue to evolve. It would be interesting to explore whether learning over task representations and meta-mappings could model some of these phenomena. Could the change in behavior on a particular task be driven by the evolution of its task representation while learning a meta-mapping involving that task? Could unsupervised learning over task representations make clusters and structure within the space of tasks salient, thereby regularizing and structuring behavior? Exploring these questions will be an exciting direction for future work.\par 

\section{Relating to artificial intelligence}

There are a number of potential direct applications in artificial intelligence, from building more flexible vision models to building better control models in robotics. Domains like robotics are especially interesting from the meta-mapping perspective, because exploration in real world settings is costly and must be safe \citep{Turchetta2016}, and so the substantial reduction in errors made when using meta-mapping as the starting point for learning a new task may be valuable. \par 

Applying meta-mapping to different types of adaptation in RL also opens many possibilites, especially in combination with model-based methods. Meta-mapping could be used as a principled way of adapting transition functions or successor representations \citep[c.f.][]{Madarasz2019}, as well as the possibility of adapting reward or value estimates as we demonstrated. Adapting pure model-free RL will likely be challenging in more complex task spaces. However, combining meta-mapping with other insights, could yield much greater flexibility. For example, meta-mapping could be used with hierarchical models where language has been used as a task or sub-task representation \citep[e.g.][]{Jiang2019}. Similarly, it could be applied in planning based model, for example using monte-carlo tree search \citep[as in e.g.][]{Silver2016, Silver2017}, but with task-representation-conditioned policy and value functions. More ambitiously, meta-mapping could be explored in models that learn to plan \citep{Guez2019} rather than having that planning hand-engineered into the architecture. Many contemporary RL frameworks could potentially be augmented with meta-mapping. \par

\section{Limitations of the present explorations}

While we have explored our results in a relatively broad range of computational paradigms, the type of flexibility we have proposed is still limited in some crucial ways. It requires exactly identifying the task to be adapted, and when that adaptation should occur (i.e. where the task boundary is). It would be more realistic to relax these assumptions. This could be achieved by combining with techniques that have been used for task-change tracking in meta-learning \citep[e.g.][]{Nagabandi2019}, but could also potentially be learned end-to-end in an appropriate model given appropriate input. There are a number of linguistic cues that humans can exploit for when they should try to adapt, and a system that experiences many such transitions might learn when adaptation is warrented. \par 

Architecturally, there are a number of aspects of the approach that could be altered. First, although we used HyperNetworks to parameterize our task network, it would also be reasonable to have a fixed task network which simply receives the task representation as an additional input. We tried this in some of our domains, and found it did not perform as well, but it might be a useful approach in some settings. We also noted in the visual cagegories domain that linear task networks seemed to improve meta-mapping, while nonlinear ones seemed to result in better basic task performance --- thus it might be reasonable to consider a deep, nonlinear task network, but with a linear skip-connection from beginning to end. Furthermore, cognitive processing is much more complex than our model, and replacing the feed-forward task network with a recurrent network, or even a more complex architecture, such as the Differentiable Neural Computer \citep{Graves2016} would likely increase the ability of the model to perform and adapt on complex tasks. These are simply examples of the many architectural choices that could be further explored given enough time and resources. \par

\section{Looking ahead}

The next ten years will likely bring us a great deal more clarity about how far deep learning is from human-like intelligence. As I suggested in the introduction, it may be that greater scale and complexity of our architectures and training regimes will bring forth more flexible behavior from our models. Indeed, this is almost certainly true to some extent --- overparameterization and more data both tend to improve the generalization of deep neural networks. Given this, what will the contribution of this dissertation be to our future knowledge? \par 

From an artificial intelligence perspective, even if more flexible behavior emerges in other architectures in richer training regimes, the architectural and training innovations I have proposed in this work may still provide useful insights that allow flexibility to emerge at more feasible data scales. Many applications of artificial intelligence (from medical diagnosis to self-driving cars) would benefit from models with greater flexibility within a family of related tasks. The perspective of building and transforming task representations may also inspire future work that leverages similar abstractions. \par 

From a cognitive science perspective, my work provides a computational basis for understanding the flexibility of the human mind. Cognitive modeling is always a trade-off between capturing details of the system and phenomena, and simplifying the system to make it more comprehensible; emergent behavior is generally harder to analyze than the behavior of simpler models. Simplified, somewhat structured models such as those we have proposed here may offer a useful level of complexity that allows for flexible behavior to be learned (rather than built in), while also making the representational and computational basis for that flexibility available to analysis. \par 

Ultimately, I have presented one computational perspective on how natural and artificial intelligence could flexibly adapt. I am excited to see the new perspectives the future will bring, and I hope my work will provide some inspiration for some of them. 
