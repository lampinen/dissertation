Transfer (multi-task):

* Regularization may hurt transfer, perhaps by preventing features that are irrelevant for this task, but relevant for others, from coming through. \citep{Kornblith2019} 


Meta-learning:
* Reptile paper: Instead of differentiating through many gradient steps, or doing first-order MAML, take many gradient steps, and then just update the initialization weights in the direction of your net update (possibly with momentum or Adam or whatever). \citep{Nichol2018} 

* Can meta-learn auxiliary tasks by optimizing for improvement on target task. \citep{Liu2019a}

* Implicit class representations for meta-learning classification, very vaguely related to EML paper \citep{Ravichandran2019}

 * Chelsea at it again, using language as an intermediate representation, but in a more-free way than Jacob Andreas, say. \citep{Jiang2019}

Generalization:

* Even if flatter minima found through learning generalize better, it is not *necessary* for a minimum to be flat for it to generalize well. relies on some (silly?) constructions where you turn a flat minimum into an arbitrarily sharp one without altering the computation, just by playing with the weights. \citep{Dinh2017} 


* information-theoretic argument for a bias toward simple outputs (in many kinds of functions) \citep{Dingle2018}

* follow-up to \citep{Dingle2018} applying these ideas to deep nets, but with a lot of strong assumptions. \citep{Perez2019} Note in the context of the previous work this form of simplicity emphatically does not apply to linear maps, and yet we're able to show good generalization driven by SGD in that setting...  



RL:

* Hindsight Experience Replay. \citep{Andrychowicz2017}

* genetic algorithms for RL \citep{Petroski2018}


