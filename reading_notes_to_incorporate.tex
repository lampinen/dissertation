Mine/proximal:

+ Emergent Systematicity paper with Felix + Adam.

* Setter-solver paper.

* Anything Arianna or Andrew Nam get out this year will almost certainly be relevant.

* My preprint from brain????


Transfer (multi-task):

+ Regularization may hurt transfer, perhaps by preventing features that are irrelevant for this task, but relevant for others, from coming through. \citep{Kornblith2019} 

    Disentanglement (relevant to transfer, since it's a kind of abstraction?):
        + Irina Higgins & colleagues define disentanglement formally in terms of symmetry groups \citep{Higgins2018}
        + A paper critical of naive notions of disentanglement, arguing that there may not be a single meaningful way in which features can be disentangled in an unsupervised way. \citep{Locatello2019}

+ Metaphors we live by: Argues that metaphors are key for cognition. \citep{Lakoff2008} 

+ Three symbol ungrounding problems: Tries to articulate some of the different concepts that go under the name of abstraction, to try to get at the issues around what grounding means. \citep{Dove2016}

+ Beyond the computer metaphor: Behavior as interaction -- argues that the closed-loop nature of behavior is missing in the brain-as-computer metaphor, and that issues like symbol grounding are non-issues when you consider what an organism or agent is actually trying to achieve. \citep{Cisek1999}

+ Resynthesizing behavior through phylogenetic refinement -- The radical version of the above, which argues that behavior should be intereprted as progressing from simple to complex over the course of evolution as was useful at each stage, essentially developing more and more complex control systems for interaction, and that this perspective provides more useful perspective for understanding than approaches that ignore it. \citep{Cisek2019}

+ Embodied Cognition: A field guide -- A useful (if slightly out of date) review to refer to and cite. \citep{Anderson2003}

* ViLBERT: Joint visual and language pre-training. \citep{Lu2019}

+ Why does unsupervised pretraining help deep learning? -- Thoroughly explores the effects of pre-training
"Unsupervised pre-training, as a regularizer that only influences the starting point of
supervised training, has an effect that, contrary to classical regularizers, does not disappear with
more data (at least as far as we can see from our results). Basically, unsupervised pre-training favors
hidden units that compute features of the input X that correspond to major factors of variation in
the true P(X). Assuming that some of these are near features useful at predicting variations in Y,
unsupervised pre-training sets up the parameters near a solution of low predictive generalization error" \citep{Erhan2010}

+ Using contextual parameters (generated in a hyper network way based on inputs for the in/out languages) for natural language translation can allow for zero-shot generalization to unseen language pairs \citep{Platanios2017}

* Better transfer learning with inferred successor maps -- Because succesor maps implicitly build the impact of the policy into the state transitions, they can be very misleading if task changes radically. This paper uses task clustering to group successor maps by relatedness of tasks to handle this problem. \citep{Madarasz2019}






Continual:

+ A recent continual learning review \citep{Parisi2019}.

+ Continual Unsupervised Representation Learning -- Unsupervised representation learning without task boundaries, based on what is effectively a generative model which infers a latent based on a mixture of task gaussians, with a dynamic expansion approach for when new tasks are added. Uses the generative model structure to allow replay and avoid catastrophic interference. Some nice developments towards more realistic settings without task boundaries. \citep{Rao2019}



Meta-learning:
+ Reptile paper: Instead of differentiating through many gradient steps, or doing first-order MAML, take many gradient steps, and then just update the initialization weights in the direction of your net update (possibly with momentum or Adam or whatever). \citep{Nichol2018} 

+ Can meta-learn auxiliary tasks by optimizing for improvement on target task. \citep{Liu2019a}

* Implicit class representations for meta-learning classification, very vaguely related to EML paper \citep{Ravichandran2019}

+ Chelsea at it again, using language as an intermediate representation, but in a more-free way than Jacob Andreas, say. \citep{Jiang2019}

+ Never-Ending Learning: Been learning to read the web for 8 years. Because of the age, takes a fairly boring knowledge graph type approach, and it's not really clear what they've achieved, but conceptually it makes some good points about what the limitations of contemporary AI are. \citep{Mitchell2018}

* Fast context adaptation via meta-learning -- alternative to MAML based on adapting just a context input to the network in the inner loop instead of all weights, results in less overfitting in some cases, and maybe more interpretable context parameters. \citep{Zintgraf2018}

* One-shot learning in discriminative neural networks -- a Bayesian one-shot learning take based on picking weights for a new classification output for new class. \citep{Burgess2016}

* Hierarchically structured meta-learning -- clusters tasks hierarchically during meta-learning \citep{Yao2019}.



Zero-shot:

+ Synthesized classifiers for zero-shot learning -- Zero-shot learning as aligning a semantic space and a classification model space as graphs, using a basis constructed from pseudo-classes which are chosen to serve as a useful basis for the known classes. This approach allows for pretty decent performance. \citep{Changpinyo2016} 

+ Zero-shot learning by convex combination of semantic embeddings -- To classify a new image, combines word vectors for old labels, weighted by how strongly the image activates those output probabilities, and then takes this hybrid word vector and uses cosine similarity to find the closest label vector, and outputs that as a label. Simple and clever. \citep{Norouzi2014}



RL:

+ Discuss task/goal-conditioned RL, and model-based methods flexibility
    + General Value Functions and task conditioning \citep{Sutton2011}

+ Imagination-augmented agents \citep{Racaniere2017}

+ SimCore

+ An investigation of model-free planning \citep{Guez2019}

* Hindsight Experience Replay. \citep{Andrychowicz2017}

* genetic algorithms for RL \citep{Petroski2018}

* Distributional RL \citep{Bellemare2017}

+ Meta-gradients \citep{Xu2018a}

+ Learning to generate matching networks \citep{Li2019a}

* Deep RL that matters -- points out that deep RL can be quite fragile to changes in hyperparameters, choices like scaling rewards, or even which codebase you're using, and argues that we should be evaluating more carefully \citep{Henderson2018}

* Optimizing agent behavior over long time scales by transporitng value -- Argues that discount-based RL will never be the right approach to solving long-term credit assignment, proposes an alternate approach based on assigning credit between times when a memory was created and when it was strongly recalled by adding a pseudo-reward at the memory creation time based on the later value, with discount not depending on intervening time. Shows that this allows for solving some LTCA tasks. \citep{Hung2019}

* Discovery of useful questions as auxiliary tasks -- uses meta-gradients to learn generalized value functions that are useful for atari game playing, and show that they are better than hand-designed ones, and improve data effiency of the agents. \citep{Veeriah2019}


Generalization:

* Add more discussion of generalization and how it relates to the issues to the intro/early sections.

* Even if flatter minima found through learning generalize better, it is not *necessary* for a minimum to be flat for it to generalize well. relies on some (silly?) constructions where you turn a flat minimum into an arbitrarily sharp one without altering the computation, just by playing with the weights. \citep{Dinh2017} 

* information-theoretic argument for a bias toward simple outputs (in many kinds of functions) \citep{Dingle2018}

* follow-up to \citep{Dingle2018} applying these ideas to deep nets, but with a lot of strong assumptions. \citep{Perez2019} Note in the context of the previous work this form of simplicity emphatically does not apply to linear maps, and yet we're able to show good generalization driven by SGD in that setting...  


Theory:

+ Saxe and colleagues point out some issues with the IB theory of deep learning \citep{Saxe2018a}.

* There exist turing-complete neural nets. \citep{Siegelman1992}.


Understanding:

* Is coding a relevant metaphor for the brain? - Argues that the idea of interpreting neural coding may be misleading, because of context dependence, the fact that the brain can't read things out as average firing rates, etc. Has relevance for how we think about interpreting AI (see below). \citep{Brette2019} 

* Is coding a relavant metaphor for building AI? Highlights the similar challenges in RL. \citep{Santoro2019}

* What's hidden in a randomly weighted neural network -- Unsurprisingly, in wide networks there are subsets of weights which perform well, builds on lottery ticket results by not even requiring optimization of the subnetwork. \citep{Ramanujan2019}

* Selective brain damage -- Pruning networks does not uniformly impact performance, instead some classes and exemplars are affected more strongly. The model seems to slightly degrade some classes in order to preserve slightly better average performance on a larger set of other classes. Exemplars that are affected by pruning (in the sense that the modal label across an ensemble changes) tend to be more ambiguous or poorly/incorrectly labeled, or just more atypical exemplars of the class. \citep{Hooker2019}


Architectures:

* Gated Linear Networks - Proposes a new deep architecture where each layer is composed of weighted geometric means of experts of the previous layer plus a bias. The weights are selected via a fixed (for that neuron, not necessarily across eurons or layers) context function, which indexes differen weight vectors. These weight vectors are learned, in fact their learning is a convex optimization problem, which can be trained *locally*, which is nice. They have both nice capacity guarantees (with rich contexts and deep networks), *and* guarantees that optimization will find the solutions. It can achieve reasonable results online (i.e. in a single epoch), at least on simple tasks. Worth implementing and playing around with, but its unclear how it would perform on something more complex. (Fixed context functions are a bit boring, what if they were learned as well? Difficult because of the hard selection though...) \citep{Veness2017} 

*+ Conditional Neural Processes - A functional gaussian-process-like interpretation of learning that bears some similarities to the way I conceptualize things in the EML paper -- should probably compare and contrast, though their motivation is more strict meta-learning and/or fill-in-the-blank type regression problems, like image completion. \citep{Garnelo2018}  (cited in intro, but should discuss further)

* FiLM (feature-wise linear modulation): A simple attention mechnaism -- affine transforms of the activations, which allows for improved performance on CLEVR etc. Worth discussing both in the context of HoMM type function adaptation, *and* as a future direction for input attention and interaction, which we know is important (drop citation to Jay in here). \citep{Perez2018}


Other:

* Deep learning for symbolic mathematics -- shows that transformer-based seq 2 seq can outperfrom mathematica at certain symbolic integration and ODE solving problems. \citep{Lample2019} 

* Composition is the core driver of the language-selective network -- As long as pairwise statistics are not too strongly violated, brain responses to sentences scrambled to have strong syntactic violations are comparable to syntactically correct sentences, suggesting that the semantics of the words that are put together, rather than whether they are grammatically assembled, is the key feature for language processing. \citep{Mollica2020}

? Language and space -- Review of the utility of different frames of reference and cultural differences from an anthropological and linguistic perspective. \citep{Levinson1996}
