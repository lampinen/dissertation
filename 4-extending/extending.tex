\chapter{Extending meta-mapping to more complex tasks} \label{chapter:extending}
In the previous chapters we have demonstrated the succes of meta-mapping in two simple domains. While these have allowed us to demonstrate the efficacy of the approach relative to other baselines, and compare its adaptation to that of humans, there are several reasons to extend beyond these to more complex tasks. \par 
First, the approach relies on several pieces which it is not obvious would scale to more complex settings, such as representing an entire task with a single vector, parameterizing the task network via a HyperNetwork conditioned on this vector, and learning meta-mappings from relatively few task examples. If any of these fails to extend to more complex settings, it could limit the applications of our approach. \par
Second, there are limitations to toy experiments. While toy experiments can provide carefully controlled demonstrations of an idea, we have shown in other work that more systematic generalization can emerge when agents are placed in more realistic settings \citep{Hill2019a}. This may impact both the meta-mapping approach and the language baseline, so it is important to evaluate the effects of richer environments on both. This will help inform us as to whether our approach will be useful in more complex settings. (Unfortunately, creating truly realistic environments and training agents in them requires complex implementations and substantial computational resources. Thus, in this chapter we demonstrate our results in environments of moderate complexity, and leave the extension to even richer environments to future work.)\par 
To address these motivations, in this chapter we present experiments on extending our ideas to two important settings: reinforcement learning and classification from raw pixel inputs. These settings are important both because they are dominant paradigms for applying deep learning, and because they have deep connections to cognitive modelling \citep[e.g.][]{Yamins2014, Kriegeskorte2015}. \par

\section{Reinforcement learning}

Reinforcement learning is an interesting application for meta-mapping for several reasons. 
