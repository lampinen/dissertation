\documentclass{report}

\usepackage{style/suthesis-2e}
\copyrightfalse
\signaturefalse

\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{epigraph}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{mathrsfs}
\usepackage{natbib}
\usepackage{relsize}
\usepackage{subcaption}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage{refcount} % allows getting around stupid issues with references in headers + upercasing

\usepackage{tikz}

\usetikzlibrary{shapes,arrows}
\usetikzlibrary{decorations.pathreplacing, decorations.pathmorphing, snakes, calligraphy}

\tikzstyle{block} = [rectangle, draw, thick, align=center, rounded corners]
\tikzstyle{boundingbox} = [thick, lightgray]
\tikzstyle{dashblock} = [rectangle, draw, thick, align=center, dashed]
\tikzstyle{conc} = [ellipse, draw, thick, dashed, align=center]
\tikzstyle{netnode} = [circle, draw, very thick, inner sep=0pt, minimum size=0.5cm]
\tikzstyle{relunode} = [rectangle, draw, very thick, inner sep=0pt, minimum size=0.5cm]
\tikzstyle{line} = [draw, very thick, -latex']
\tikzstyle{arrow} = [draw, ->, thick]

\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}

\definecolor{bpurp}{HTML}{984ea3}
\definecolor{bblue}{HTML}{377eb8}
\definecolor{bgreen}{HTML}{4daf4a}
\definecolor{borange}{HTML}{ff7f00}

% footnote without a marker
\makeatletter
\def\blfootnote{\gdef\@thefnmark{}\@footnotetext} 
\makeatother

\include{header/header}

\dept{Psychology}

\begin{document}
\title{Toward understanding human adaptibility with deep learning models}
\author{Andrew Kyle Lampinen}
\principaladviser{Jay McClelland}
\firstreader{Noah Goodman}
\secondreader{Surya Ganguli}
%\thirdreader{Jane Supernumerary} %if needed
%\fourthreader{Severus Snape} %if needed

\beforepreface
\setcounter{page}{4}  % Stanford formatting requirements
\prefacesection{Abstract}

Human cognition is fundamentally flexible --- we can adapt to a novel task without any direct experience on that task, based on its relationship to previous tasks. By contrast, while deep-learning models can achieve superhuman performance on many tasks, they are unable to adapt to even slight task alterations. I begin this dissertation by reviewing the literature on cognitive flexibility, and recent advances in artificial intelligence. I provide a synthesis of these literatures, and outline the challenges that I believe remain. In particular, I focus on the ability to adapt to new tasks zero-shot, that is, without any data.\par
To address this challenge, I propose a general computational framework for modeling adaptation to novel tasks based on their relationship to prior tasks. The framework is based on \emph{meta-mappings}, higher-order tasks that transform basic tasks. I propose a parsimonious implementation of this framework in the form of \emph{homoiconic meta-mapping} architectures. I demonstrate this framework across a wide variety of tasks and computational paradigms, ranging from regression to image classification and reinforcement learning. I compare to both human adaptibility, and language-based approaches to zero-shot task performance. I demonstrate that the model is extremely succesful, often achieveing 80-90\% performance on a novel task that directly contradicts its prior experience. I further show that using this adaptation as a starting point can dramatically accelerate later learning on a task, and reduce the errors made on the way to mastery by nearly an order of magnitude. \par
Thus, I suggest that meta-mapping provides a plausible computational basis for human adaptability and efficient learning. This dissertation therefore provides a framework for building better cognitive models and more flexible artificial intelligence systems. In the final chapter, I review the broader contributions of this work to an ongoing discussion about the computational principles necessary for intelligence, and highlight possible future directions ranging from understanding mathematical cognition to neuroscience. 

\afterpreface

\include{1-introduction/introduction}
\include{2-HoMM/homoiconic_meta_mapping_main}
\include{3-human-adaptation/human-adaptation}
\include{4-extending/extending}
\include{5-timescales/timescales}
\include{6-conclusions/conclusions}

%\include{outline}

\appendix

\include{2-HoMM/homoiconic_meta_mapping_appendix}
\include{3-human-adaptation/human-adaptation-supplement}
\include{4-extending/extending-supplement}

\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{apalike}
\bibliography{arrr}

\end{document}
