\chapter{Learning across different timescales} \label{chapter:timescales}

%% TODO: probably mention SWIL somewhere in these first few paragraphs
A large amount of recent machine learning research can be seen as studying interactions of learning across different time-scales. In particular, the field of meta-learning is based on the idea that a model can slowly learn over many experiences how to learn rapidly in a new experience. Similarly, the previous chapters show how slowly-accumulated knowledge about tasks and their relationships can allow zero-shot inferences about a new task. \par 

However, both of these approaches examine how slowly learned knowledge can improve rapid learning. Yet one of the core motivations of complementary learning systems theory was that rapidly learned experiences could be integrated into our prior knowledge. There is a lack of research investigating how what we learn over short time scales, for example in the inner loop of a meta-learning algorithm, can be integrated with our longer term knowledge. \par 

Integration of knowledge in machine learning is mostly studied under the continual learning. Most work on continual learning investigates the setting where a model, starting from \emph{tabular rasa}, must learn a sequence of tasks without forgetting \citep{Ven2018, Atkinson2018}. This is motivated by the clear ability of humans and animals to learn multiple tasks without forgetting. However, humans are not starting from a blank slate when they achieve this. Indeed, \citep{Velez2017} show that systems can meta-learn to learn without forgetting. This raises the possibility that works that examine continual learning from a blank slate are misleading, because prior learning can be an important part of the solution. \par 

We have shown in the prior chapters that using knowledge of prior tasks can allow the system to perform well on a new, related task without any data. Here, we highlight the impacts of this perspective on different time-scales of learning. In particular, we first show that this zero-shot inference improves learning on the new task, and second, that the knowledge encoded in the system can allow this learning to occur without even the possibility of interference with prior tasks. \par  

\section{Starting points for learning}

When humans arrive at a novel task, we often receive some instructions as a starting point. These instructions often describe the relationship of the novel task to prior experiences. This observation served as the motivation for the previous chapters, in which we showed that using meta-mapping could improve zero-shot task performance. However, as soon as we start performing a task, it is no longer zero-shot. That is, zero-shot adaptation is most important insofar as it serves as a useful starting point for later learning. In this chapter, one of our primary goals is to compare the zero-shot ``guess'' at a task representation to other initializations of the task representation, to evaluate whether it is a beneficial starting point for learning. \par 
In order to do this, we use an approach related to our prior work on one-shot learning of word embeddings \citep{Lampinen2018a}. In that work, we integrated a novel word into a pre-trained language model by simply optimizing its embedding(s) to improve the model's prediction of it in context. We showed that this allowed reasonable learning of new words, in fact average performance with this method was not statistically different than if the word had been included in the training corpus from the beginning. Thus in a model that has been pre-trained to understand the latent structure of a system (such as language), optimizing the representation of a single object can often be sufficient to construct a high-quality representation of the object, without needing to alter the other parameters of the model. \par
%% TODO: SWIL here as well.
Analogously, in this chapter we explore optimizing the task embedding of a novel task once the system has begun to perform it. We will show that optimizing the task embedding alone will often allow near-perfect performance on a novel task, provided the model that is pre-trained on sufficiently many other tasks from the same distribution. This means that a new task can be learned without the possibility of any interference with prior tasks, because only task-specific parameters are altered. This provides a new perspective on continual learning (though see \citep{Oswald2020} for some related observations). Rather than thinking about how a system can minimize interference when learning a sequence of tasks from \emph{tabula rasa}, we should perhaps ask how prior knowledge can allow learning without any interference at all. \par 
The important observation from our perspective is that a zero-shot guess at a task embedding provides a useful starting point for this optimization. In particular, we compare to a variety of other initializations, and show that the zero-shot guess provides faster learning, and lower cumulative error. This latter measure can be thought of as analogous to the notion of \emph{regret} in reinforcement learning, a measure of how sub-optimally the algorithm performs while learning to behave optimally. Starting from the output of a meta-mapping results in learning faster, and making fewer mistakes along the way. This may be part of the solution to why humans are able to learn faster and more accurately than deep learning models on novel tasks. \par   

\section{The polynomials domain}

%% TODO: add updated results and baseline in untrained model 
We begin by demonstrating these results in the simple polynomial regression domain that we considered in chapter \ref{chapter:zero_shot_via_homm}. We compare three different initializations. First, a small random initialization, as is often used for parameters of a deep model prior to training. Second, initializing each task with the embedding of a random trained task, in case the distributions of these is helpful for later learning. Finally, we compare to the guess embedding produced by meta-mapping from a prior task. \par 
As noted above, we make this comparison by optimizing the task embeddings for the new tasks. We do this without altering any other parameters in the model. It is not clear that this would be sufficient to produce good performance on a novel task, indeed we show below that in an untrained model it is not. However, if the model has sufficient experience of related tasks, it does suffice. \par 
We used a similar distribution of tasks to our polynomial results presented above, except that we ensured every evaluation task was a trained meta-mapping of a trained task, but where that task had not been used as an example for the meta-mapping during training. This eliminates the uncertainty introduced by having to learn a new task or mapping from examples, as well as applying the transformation, which allows for a more controlled comparison. To be precise, we trained the system on 60 base tasks plus the results of applying 20 meta-mappings to them. We additionally trained the system on 40 new base tasks, and held out the results of applying the 20 meta-mappings to them. It is these \(40 \times 20 = 800\) novel tasks that we optimized the embeddings for. \par 

